{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import zipfile\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nltk.download()\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# download train data (Kaggle)\n",
    "with zipfile.ZipFile('labeledTrainData.tsv.zip') as file:\n",
    "    with file.open(file.namelist()[0]) as content:\n",
    "        train = pd.read_csv(content, header=0, delimiter=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_to_words(raw_review, remove_stopwords=False):\n",
    "    '''turning reviews into list of words'''\n",
    "    # parsing html\n",
    "    review_text = BeautifulSoup(raw_review,'lxml').get_text()\n",
    "    # leaving only letters\n",
    "    letters_only=re.sub('[^a-zA-Z]',\" \",review_text)\n",
    "    words = letters_only.lower().split()\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\")) \n",
    "        words =  [w for w in words if w not in stops]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I dont know why people think this is such a bad movie. Its got a pretty good plot, some good action, and the change of location for Harry does not hurt either. Sure some of its offensive and gratuitous but this is not the only movie like that. Eastwood is in good form as Dirty Harry, and I liked Pat Hingle in this movie as the small town cop. If you liked DIRTY HARRY, then you should see this one, its a lot better than THE DEAD POOL. 4/5\"\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "# raw input\n",
    "print(train.review[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i dont know why people think this is such a bad movie its got a pretty good plot some good action and the change of location for harry does not hurt either sure some of its offensive and gratuitous but this is not the only movie like that eastwood is in good form as dirty harry and i liked pat hingle in this movie as the small town cop if you liked dirty harry then you should see this one its a lot better than the dead pool\n"
     ]
    }
   ],
   "source": [
    "# processed input\n",
    "print(review_to_words(train.review[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 25000 of 25000\n"
     ]
    }
   ],
   "source": [
    "# make a list of clean reviews\n",
    "num_reviews = train.shape[0]\n",
    "clean_reviews = []\n",
    "\n",
    "for i in range(num_reviews):\n",
    "    if (i+1) % 5000 == 0:\n",
    "        clear_output()\n",
    "        print(\"Review {0:d} of {1:d}\".format(i+1,num_reviews))\n",
    "    clean_reviews.append(review_to_words(train.review[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i dont know why people think this is such a bad movie its got a pretty good plot some good action and the change of location for harry does not hurt either sure some of its offensive and gratuitous but this is not the only movie like that eastwood is in good form as dirty harry and i liked pat hingle in this movie as the small town cop if you liked dirty harry then you should see this one its a lot better than the dead pool\n"
     ]
    }
   ],
   "source": [
    "print(clean_reviews[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CountVectorizer converts a collection of text documents to a matrix of token counts\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000)\n",
    "\n",
    "train_data_features = vectorizer.fit_transform(clean_reviews).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 5000)\n"
     ]
    }
   ],
   "source": [
    "# number of reviews by vocabluary size\n",
    "print(train_data_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size = 5000 True\n"
     ]
    }
   ],
   "source": [
    "# get vocabluary\n",
    "vocab = vectorizer.get_feature_names()\n",
    "dist  = np.sum(train_data_features,axis=0)\n",
    "print('Vocab size =', len(vocab), len(vocab)==len(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# counts number of times each word encounters in the text\n",
    "#for tag,count in zip(vocab,dist):\n",
    "#    print(\"{0:12s}: {1:d}\".format(tag, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train_data_features\n",
    "y = train.sentiment\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling 1: Random Forrests (Sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 29.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "forest = RandomForestClassifier(n_estimators=100,oob_score=True,n_jobs=-1)\n",
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on OOB data:   0.901645449592\n",
      "AUC on test data:  0.91476558905\n"
     ]
    }
   ],
   "source": [
    "p_test = forest.predict_proba(X_test)[:,1]\n",
    "p_oob  = forest.oob_decision_function_[:,1]\n",
    "print('AUC on OOB data:  ',metrics.roc_auc_score(y_train,p_oob))\n",
    "print('AUC on test data: ',metrics.roc_auc_score(y_test,p_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling 2: Linear Neural Network (PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build a model\n",
    "class BOW_classifier(nn.Module):\n",
    "    def __init__(self,num_labels,vocab_size):\n",
    "        super(BOW_classifier,self).__init__()\n",
    "        self.linear1 = nn.Linear(vocab_size,100)\n",
    "        self.linear2 = nn.Linear(100,20)\n",
    "        self.linear3 = nn.Linear(20,num_labels)\n",
    "    \n",
    "    def forward(self,bow_vec):\n",
    "        out1 = F.relu(self.linear1(bow_vec))\n",
    "        out2 = F.relu(self.linear2(out1))\n",
    "        return F.log_softmax(self.linear3(out2))\n",
    "    \n",
    "model = BOW_classifier(2,vocab_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.56808984]\n",
      "10 [ 0.36756164]\n",
      "20 [ 0.32868358]\n",
      "30 [ 0.20889403]\n",
      "40 [ 0.20131597]\n",
      "Wall time: 46.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 200\n",
    "num_batches = X_train.shape[0]//batch_size\n",
    "\n",
    "loss_fun = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.1)\n",
    "\n",
    "for epoch in range(50):\n",
    "    for i in range(num_batches):\n",
    "        k = i*batch_size\n",
    "        model.zero_grad()\n",
    "        batch  = Variable(torch.from_numpy(X_train[k:k+batch_size,:]).type(torch.FloatTensor))\n",
    "        target = Variable(torch.from_numpy(y_train.values[k:k+batch_size]))\n",
    "        \n",
    "        log_probs = model(batch)\n",
    "        loss = loss_fun(log_probs,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(epoch, loss.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on train data:  0.989408156187\n",
      "AUC on test data:   0.939915973916\n"
     ]
    }
   ],
   "source": [
    "p_test  = torch.exp(model(Variable(torch.from_numpy(X_test).type(torch.FloatTensor))).data[:,1]).numpy()\n",
    "p_train = torch.exp(model(Variable(torch.from_numpy(X_train).type(torch.FloatTensor))).data[:,1]).numpy()\n",
    "\n",
    "print('AUC on train data: ',metrics.roc_auc_score(y_train,p_train))\n",
    "print('AUC on test data:  ',metrics.roc_auc_score(y_test,p_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
